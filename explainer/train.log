Finetune model...
Epoch 0, Loss: 5.9982, Patience: 0, Recall: 0.0351
Epoch 1, Loss: 5.8320, Patience: 0, Recall: 0.0751
Epoch 2, Loss: 5.6296, Patience: 0, Recall: 0.1278
Epoch 3, Loss: 5.3296, Patience: 0, Recall: 0.1688
Epoch 4, Loss: 4.9817, Patience: 0, Recall: 0.1805
Epoch 5, Loss: 4.5867, Patience: 0, Recall: 0.1844
Epoch 6, Loss: 4.1205, Patience: 1, Recall: 0.1834
Epoch 7, Loss: 3.6207, Patience: 0, Recall: 0.1873
Epoch 8, Loss: 3.3603, Patience: 0, Recall: 0.1883
Epoch 9, Loss: 2.9383, Patience: 0, Recall: 0.1932
Epoch 10, Loss: 2.6545, Patience: 0, Recall: 0.1971
Epoch 11, Loss: 2.4150, Patience: 0, Recall: 0.2000
Epoch 12, Loss: 2.1635, Patience: 0, Recall: 0.2049
Epoch 13, Loss: 1.9803, Patience: 1, Recall: 0.2049
Epoch 14, Loss: 1.8149, Patience: 2, Recall: 0.2029
Epoch 15, Loss: 1.6547, Patience: 3, Recall: 0.2039
Epoch 16, Loss: 1.5670, Patience: 4, Recall: 0.2049
Epoch 17, Loss: 1.4268, Patience: 5, Recall: 0.2029
Epoch 18, Loss: 1.3403, Patience: 6, Recall: 0.2039
Epoch 19, Loss: 1.1780, Patience: 0, Recall: 0.2078
Epoch 20, Loss: 1.1374, Patience: 0, Recall: 0.2088
Epoch 21, Loss: 1.1147, Patience: 1, Recall: 0.2078
Epoch 22, Loss: 0.9802, Patience: 0, Recall: 0.2107
Epoch 23, Loss: 0.9216, Patience: 0, Recall: 0.2137
Epoch 24, Loss: 0.8374, Patience: 1, Recall: 0.2127
Epoch 25, Loss: 0.8144, Patience: 2, Recall: 0.2127
Epoch 26, Loss: 0.7773, Patience: 0, Recall: 0.2156
Epoch 27, Loss: 0.7155, Patience: 1, Recall: 0.2146
Epoch 28, Loss: 0.6908, Patience: 2, Recall: 0.2137
Epoch 29, Loss: 0.6651, Patience: 3, Recall: 0.2146
Epoch 30, Loss: 0.6218, Patience: 4, Recall: 0.2156
Epoch 31, Loss: 0.5899, Patience: 5, Recall: 0.2146
Epoch 32, Loss: 0.5627, Patience: 6, Recall: 0.2146
Epoch 33, Loss: 0.5866, Patience: 7, Recall: 0.2117
Epoch 34, Loss: 0.5501, Patience: 8, Recall: 0.2088
Epoch 35, Loss: 0.5106, Patience: 9, Recall: 0.2059
Epoch 36, Loss: 0.5056, Patience: 10, Recall: 0.2049
Training finished
Best Recall: 0.2156, NDCG: 0.0935, Precision: 0.0184, MRR: 0.0740
  1%|███                                                                                                                                                                                                                                                           | 49/4102 [00:56<1:17:52,  1.15s/it]Epoch [0/3], Step [49/4102], Loss: 4.9190168380737305
Generated Explanation: tensor([[[-0.0586, -0.3049,  0.3765,  ...,  2.3984, -1.7070, -1.9785],
         [-0.0586, -0.3049,  0.3765,  ...,  2.3984, -1.7070, -1.9785],
         [-6.1211, -0.3208,  0.5645,  ...,  1.5303, -1.2178, -4.1797],
         ...,
         [-5.6328, -2.7949,  2.5859,  ...,  2.0430,  0.4702, -0.9360],
         [-5.2891, -2.7520,  2.8340,  ...,  2.2031,  0.1791, -0.8516],
         [-5.4375, -2.9258,  2.4297,  ...,  2.2031,  0.2042, -0.7568]],

        [[-0.0586, -0.3049,  0.3765,  ...,  2.3984, -1.7070, -1.9785],
         [-0.0586, -0.3049,  0.3765,  ...,  2.3984, -1.7070, -1.9785],
         [-6.1211, -0.3208,  0.5645,  ...,  1.5303, -1.2178, -4.1797],
         ...,
         [ 0.8423, -2.7871, -0.6499,  ..., -1.5234, -2.9512, -0.5576],
         [-4.5508, -6.0039,  1.1992,  ...,  2.5020, -3.8125, -3.9688],
         [-4.0391, -2.7324,  5.6367,  ..., -0.5776, -2.8008, -2.2344]]],
       device='cuda:0', grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                       | 99/4102 [01:53<1:17:16,  1.16s/it]Epoch [0/3], Step [99/4102], Loss: 8.435966491699219
Generated Explanation: tensor([[[-0.0371, -0.2554,  0.3838,  ...,  2.4004, -1.6738, -2.0020],
         [-0.0371, -0.2554,  0.3838,  ...,  2.4004, -1.6738, -2.0020],
         [-6.0703, -0.5806,  0.7271,  ...,  1.5322, -0.9946, -4.4844],
         ...,
         [ 0.2145, -0.8794,  4.3789,  ..., -1.4561, -1.0684, -0.0444],
         [-4.4492, -8.7891,  1.2031,  ..., -0.0165, -4.3828, -4.7227],
         [-3.4570, -2.9004,  6.2695,  ..., -0.2537, -1.8379, -2.3438]],

        [[-0.0371, -0.2554,  0.3838,  ...,  2.4004, -1.6738, -2.0020],
         [-0.0371, -0.2554,  0.3838,  ...,  2.4004, -1.6738, -2.0020],
         [-6.0703, -0.5806,  0.7271,  ...,  1.5322, -0.9946, -4.4844],
         ...,
         [-1.2109,  0.5391,  4.2695,  ...,  2.0195, -1.3213, -0.2384],
         [-1.1865,  0.6572,  4.3242,  ...,  1.9365, -1.3818, -0.2566],
         [-1.1924,  0.6089,  4.2031,  ...,  2.0469, -1.2910, -0.3613]]],
       device='cuda:0', grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                      | 100/4102 [01:55<1:16:54,  1.15s/it]
Epoch [0/3], Loss: 581.4366765022278
Saved model to ./data/archive/user_converter_test.pkl
Saved model to ./data/archive/item_converter_test.pkl
Epoch 0, Loss: 0.5024, Patience: 0, Recall: 0.2059
Epoch 1, Loss: 0.4226, Patience: 1, Recall: 0.2049
Epoch 2, Loss: 0.3767, Patience: 2, Recall: 0.2020
Epoch 3, Loss: 0.3633, Patience: 3, Recall: 0.2029
Epoch 4, Loss: 0.3426, Patience: 4, Recall: 0.2039
Epoch 5, Loss: 0.3412, Patience: 5, Recall: 0.2020
Epoch 6, Loss: 0.3143, Patience: 6, Recall: 0.1961
Epoch 7, Loss: 0.3102, Patience: 7, Recall: 0.1941
Epoch 8, Loss: 0.3011, Patience: 8, Recall: 0.1932
Epoch 9, Loss: 0.3038, Patience: 9, Recall: 0.1951
Epoch 10, Loss: 0.2948, Patience: 10, Recall: 0.1961
Training finished
Best Recall: 0.2059, NDCG: 0.0878, Precision: 0.0175, MRR: 0.0672
  1%|███                                                                                                                                                                                                                                                           | 49/4102 [00:56<1:17:48,  1.15s/it]Epoch [1/3], Step [49/4102], Loss: 4.750432014465332
Generated Explanation: tensor([[[-0.0768, -0.3162,  0.3652,  ...,  2.3965, -1.7041, -1.9980],
         [-0.0768, -0.3162,  0.3652,  ...,  2.3965, -1.7041, -1.9980],
         [-6.1719, -0.4856,  0.8477,  ...,  1.6582, -1.1016, -4.3320],
         ...,
         [-5.0352, -3.1680,  2.3398,  ...,  2.1133,  0.4531, -0.3596],
         [-5.4258, -3.3027,  2.7324,  ...,  2.0176,  0.7910, -0.1945],
         [-5.3633, -3.5156,  2.7227,  ...,  2.3613,  0.6582, -0.1637]],

        [[-0.0768, -0.3162,  0.3652,  ...,  2.3965, -1.7041, -1.9980],
         [-0.0768, -0.3162,  0.3652,  ...,  2.3965, -1.7041, -1.9980],
         [-6.1719, -0.4856,  0.8477,  ...,  1.6582, -1.1016, -4.3320],
         ...,
         [ 1.1650, -3.2012, -0.4548,  ..., -1.4688, -2.9141,  0.1677],
         [-4.6719, -6.4180,  1.4443,  ...,  1.9170, -3.6504, -3.5859],
         [-4.0781, -3.6191,  5.1055,  ..., -0.8657, -2.1113, -1.9795]]],
       device='cuda:0', grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                       | 99/4102 [01:53<1:16:45,  1.15s/it]Epoch [1/3], Step [99/4102], Loss: 7.875103950500488
Generated Explanation: tensor([[[-9.0454e-02, -3.0420e-01,  4.0454e-01,  ...,  2.4121e+00,
          -1.6729e+00, -1.9932e+00],
         [-9.0454e-02, -3.0420e-01,  4.0454e-01,  ...,  2.4121e+00,
          -1.6729e+00, -1.9932e+00],
         [-6.0508e+00, -2.8735e-01,  6.7139e-01,  ...,  1.5068e+00,
          -1.1143e+00, -4.2031e+00],
         ...,
         [ 2.3352e-01, -1.0488e+00,  3.9902e+00,  ..., -1.0947e+00,
          -7.8662e-01,  7.2754e-01],
         [-5.2109e+00, -9.6094e+00,  1.0605e+00,  ...,  3.0591e-01,
          -3.8184e+00, -5.5938e+00],
         [-3.4082e+00, -2.7070e+00,  6.4336e+00,  ..., -5.9521e-01,
          -1.5723e+00, -1.8662e+00]],

        [[-9.0454e-02, -3.0420e-01,  4.0454e-01,  ...,  2.4121e+00,
          -1.6729e+00, -1.9932e+00],
         [-9.0454e-02, -3.0420e-01,  4.0454e-01,  ...,  2.4121e+00,
          -1.6729e+00, -1.9932e+00],
         [-6.0508e+00, -2.8735e-01,  6.7139e-01,  ...,  1.5068e+00,
          -1.1143e+00, -4.2031e+00],
         ...,
         [-1.6064e+00,  1.6138e-01,  4.2148e+00,  ...,  1.8213e+00,
          -1.0898e+00, -1.7456e-02],
         [-1.6592e+00, -7.7171e-03,  4.0312e+00,  ...,  1.9121e+00,
          -1.0508e+00, -1.6052e-02],
         [-1.6963e+00, -1.5701e-02,  4.3125e+00,  ...,  1.8564e+00,
          -1.1338e+00, -1.2372e-01]]], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                      | 100/4102 [01:54<1:16:27,  1.15s/it]
Epoch [1/3], Loss: 485.90700697898865
Saved model to ./data/archive/user_converter_test.pkl
Saved model to ./data/archive/item_converter_test.pkl
Epoch 0, Loss: 0.2860, Patience: 0, Recall: 0.1922
Epoch 1, Loss: 0.2820, Patience: 1, Recall: 0.1912
Epoch 2, Loss: 0.2799, Patience: 2, Recall: 0.1922
Epoch 3, Loss: 0.2664, Patience: 3, Recall: 0.1902
Epoch 4, Loss: 0.2677, Patience: 4, Recall: 0.1893
Epoch 5, Loss: 0.2594, Patience: 5, Recall: 0.1873
Epoch 6, Loss: 0.2619, Patience: 6, Recall: 0.1824
Epoch 7, Loss: 0.2561, Patience: 7, Recall: 0.1785
Epoch 8, Loss: 0.2541, Patience: 8, Recall: 0.1776
Epoch 9, Loss: 0.2522, Patience: 9, Recall: 0.1776
Epoch 10, Loss: 0.2510, Patience: 10, Recall: 0.1746
Training finished
Best Recall: 0.1922, NDCG: 0.0793, Precision: 0.0164, MRR: 0.0582
  1%|███                                                                                                                                                                                                                                                           | 49/4102 [00:55<1:17:46,  1.15s/it]Epoch [2/3], Step [49/4102], Loss: 3.7685067653656006
Generated Explanation: tensor([[[-0.0493, -0.2676,  0.3665,  ...,  2.4141, -1.6689, -1.9941],
         [-0.0493, -0.2676,  0.3665,  ...,  2.4141, -1.6689, -1.9941],
         [-6.1680, -0.4678,  0.7344,  ...,  1.3643, -1.1104, -4.2773],
         ...,
         [-5.6250, -3.6719,  0.7231,  ...,  1.4941,  0.5664,  1.7666],
         [-5.9766, -4.2656,  0.6138,  ...,  1.4365,  0.4275,  1.6592],
         [-6.1484, -4.6055,  0.5083,  ...,  1.6621,  0.3936,  1.4814]],

        [[-0.0493, -0.2676,  0.3665,  ...,  2.4141, -1.6689, -1.9941],
         [-0.0493, -0.2676,  0.3665,  ...,  2.4141, -1.6689, -1.9941],
         [-6.1680, -0.4678,  0.7344,  ...,  1.3643, -1.1104, -4.2773],
         ...,
         [ 1.3799, -3.0820, -1.0029,  ..., -1.5811, -3.4941,  0.5269],
         [-4.6367, -5.7734,  1.1777,  ...,  2.6211, -4.3203, -3.2480],
         [-4.0469, -4.5039,  3.9707,  ..., -0.5601, -2.7051, -1.5674]]],
       device='cuda:0', grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                       | 99/4102 [01:53<1:17:27,  1.16s/it]Epoch [2/3], Step [99/4102], Loss: 6.979226112365723
Generated Explanation: tensor([[[-0.0334, -0.2825,  0.3748,  ...,  2.4297, -1.6660, -1.9482],
         [-0.0334, -0.2825,  0.3748,  ...,  2.4297, -1.6660, -1.9482],
         [-6.1914, -0.8813,  0.7275,  ...,  1.7227, -1.0469, -4.3789],
         ...,
         [ 0.5752, -0.6362,  2.6973,  ..., -1.2188, -1.5059,  0.4673],
         [-5.2695, -9.0781,  0.2942,  ...,  0.1482, -4.5508, -4.9492],
         [-3.6289, -4.1836,  6.0273,  ..., -1.0840, -1.8008, -2.5215]],

        [[-0.0334, -0.2825,  0.3748,  ...,  2.4297, -1.6660, -1.9482],
         [-0.0334, -0.2825,  0.3748,  ...,  2.4297, -1.6660, -1.9482],
         [-6.1914, -0.8813,  0.7275,  ...,  1.7227, -1.0469, -4.3789],
         ...,
         [-1.7979, -0.3828,  3.7969,  ...,  1.9824, -1.1670,  0.2146],
         [-2.1797, -0.7329,  3.5547,  ...,  1.7930, -1.3242,  0.0862],
         [-2.3984, -1.0625,  3.5566,  ...,  1.8350, -1.4912,  0.1938]]],
       device='cuda:0', grad_fn=<ToCopyBackward0>)
  2%|██████▏                                                                                                                                                                                                                                                      | 100/4102 [01:54<1:16:23,  1.15s/it]
Epoch [2/3], Loss: 409.7554713487625
Saved model to ./data/archive/user_converter_test.pkl
Saved model to ./data/archive/item_converter_test.pkl